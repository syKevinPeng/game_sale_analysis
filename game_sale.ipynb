{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![Image of Yaktocat](https://cdn.mos.cms.futurecdn.net/rLh7Dh7EKo8F6zmDtXYp8W.jpg)\n",
    "# Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Install packages](#install-pkg)\n",
    "3. [Data Dowloading](#data-download)\n",
    "4. [Preprocessing](#preprocessing)<br>\n",
    "    a. [Load and Clean Dataset](#load-and-clean)<br>\n",
    "    b. [Data Analysis and Visualization](#data-ana-vis)\n",
    "5. [Machine Learning Model](#ml-model)<br>\n",
    "    a. [What and Why](#what-why)<br>\n",
    "    b. [Training](#training)<br>\n",
    "    c. [Result Anlysis and Demonstration](#result-ana-demon)\n",
    "6. [Future Application](#future-app)\n",
    "7. [Reference and External Link](#ref-and-extlink)\n",
    "\n",
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "Have you dreamed about strolling around a dystopian metropole where violence, oppression, and cyberware implants aren't just common in 2077?\n",
    "Have you dreamed about holding a Great Sword fight against a giant ancient dragon in Monster World?\n",
    "Have you dreamed about driving Bugatti Veyron Super Sport in the city and all your opponents are in your rear mirror?\n",
    "Playing video games seems to be a more and more popular entertainment options for people, especially in the middle of pandemic.\n",
    "Gaming market values are almost double from 2012 to 2020. It's now a 150 billion industry with almost 10 thousands of game produced each year.\n",
    "In this project, we are interested in what makes a game popular and how much revenue it may generate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Install Packages <a name=\"install-pkg\"></a>\n",
    "```\n",
    "pip install kaggle numpy matplotlib pandas sklearn\n",
    "```\n",
    "or use [environment.yml](https://github.com/syKevinPeng/game_sale_analysis/blob/main/environment.yml) to install packages in Conda environment\n",
    "```\n",
    "conda env update -f environment.yml\n",
    "```\n",
    "## 3. Data Downloading <a name=\"data-download\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-games-sales-2019.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "# remember to put kaggle.json to your C:/username/.kaggle\n",
    "!kaggle datasets download -d ashaheedq/video-games-sales-2019"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "or directly download from kaggle webpage: [https://www.kaggle.com/ashaheedq/video-games-sales-2019](https://www.kaggle.com/ashaheedq/video-games-sales-2019)_\n",
    "## 4. Preprocessing <a name=\"preprocessing\"></a>\n",
    "In this section, we will load and process the two datasets: \"vgsales-12-4-2019.csv\" is our main dataset and \"video_games.csv\"\n",
    "is a complementary dataset we will use to fill in  important missing values like \"Global_Sales\" and \"Critic_Score\" in the first dataset.\n",
    "**Datasets**\n",
    "\n",
    "\"vgsales-12-4-2019.csv\" is a kaggle dataset with around 50000 records of game sales collected in 2019.\n",
    "There are missing values in the column \"Global_Sales\", since this column is the predicted value for our model training,\n",
    "we load another dataset \"video_games.csv\" to fill in these values as many as possible and drop the rest N/A values.\n",
    "\n",
    "\"video_games.csv\" is a dataset of Steam game sales,\n",
    " we load it from [this repository](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-07-30).\n",
    " It has a cloumn \"owners\" which includes a range of the number of players that own each game,\n",
    " we take the expected value (or median) of every range as the replacement for the missing data in the first dataset,\n",
    " and we will do the same for the missing values in \"Critic_Score\". To merge the two datasets after doing necessary\n",
    " processing, we will use a LEFT JOIN based on the columns \"Name\" and \"Year\".\n",
    "### 4.a. Load and Clean Data <a name=\"load-and-clean\"></a>\n",
    "In the following cells we import the libraries,load the datasets using pandas.read_csv() function, and reate a preview of the datasets using df.head() function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   Rank                           Name                      basename  \\\n0     1                     Wii Sports                    wii-sports   \n1     2              Super Mario Bros.              super-mario-bros   \n2     3                 Mario Kart Wii                mario-kart-wii   \n3     4  PlayerUnknown's Battlegrounds  playerunknowns-battlegrounds   \n4     5              Wii Sports Resort             wii-sports-resort   \n\n      Genre ESRB_Rating Platform         Publisher         Developer  \\\n0    Sports           E      Wii          Nintendo      Nintendo EAD   \n1  Platform         NaN      NES          Nintendo      Nintendo EAD   \n2    Racing           E      Wii          Nintendo      Nintendo EAD   \n3   Shooter         NaN       PC  PUBG Corporation  PUBG Corporation   \n4    Sports           E      Wii          Nintendo      Nintendo EAD   \n\n   VGChartz_Score  Critic_Score  ...  NA_Sales  PAL_Sales  JP_Sales  \\\n0             NaN           7.7  ...       NaN        NaN       NaN   \n1             NaN          10.0  ...       NaN        NaN       NaN   \n2             NaN           8.2  ...       NaN        NaN       NaN   \n3             NaN           NaN  ...       NaN        NaN       NaN   \n4             NaN           8.0  ...       NaN        NaN       NaN   \n\n   Other_Sales    Year  Last_Update  \\\n0          NaN  2006.0          NaN   \n1          NaN  1985.0          NaN   \n2          NaN  2008.0  11th Apr 18   \n3          NaN  2017.0  13th Nov 18   \n4          NaN  2009.0          NaN   \n\n                                                 url  status Vgchartzscore  \\\n0  http://www.vgchartz.com/game/2667/wii-sports/?...       1           NaN   \n1  http://www.vgchartz.com/game/6455/super-mario-...       1           NaN   \n2  http://www.vgchartz.com/game/6968/mario-kart-w...       1           8.7   \n3  http://www.vgchartz.com/game/215988/playerunkn...       1           NaN   \n4  http://www.vgchartz.com/game/24656/wii-sports-...       1           8.8   \n\n                                         img_url  \n0  /games/boxart/full_2258645AmericaFrontccc.jpg  \n1                   /games/boxart/8972270ccc.jpg  \n2  /games/boxart/full_8932480AmericaFrontccc.jpg  \n3  /games/boxart/full_8052843AmericaFrontccc.jpg  \n4  /games/boxart/full_7295041AmericaFrontccc.jpg  \n\n[5 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Rank</th>\n      <th>Name</th>\n      <th>basename</th>\n      <th>Genre</th>\n      <th>ESRB_Rating</th>\n      <th>Platform</th>\n      <th>Publisher</th>\n      <th>Developer</th>\n      <th>VGChartz_Score</th>\n      <th>Critic_Score</th>\n      <th>...</th>\n      <th>NA_Sales</th>\n      <th>PAL_Sales</th>\n      <th>JP_Sales</th>\n      <th>Other_Sales</th>\n      <th>Year</th>\n      <th>Last_Update</th>\n      <th>url</th>\n      <th>status</th>\n      <th>Vgchartzscore</th>\n      <th>img_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Wii Sports</td>\n      <td>wii-sports</td>\n      <td>Sports</td>\n      <td>E</td>\n      <td>Wii</td>\n      <td>Nintendo</td>\n      <td>Nintendo EAD</td>\n      <td>NaN</td>\n      <td>7.7</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2006.0</td>\n      <td>NaN</td>\n      <td>http://www.vgchartz.com/game/2667/wii-sports/?...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>/games/boxart/full_2258645AmericaFrontccc.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Super Mario Bros.</td>\n      <td>super-mario-bros</td>\n      <td>Platform</td>\n      <td>NaN</td>\n      <td>NES</td>\n      <td>Nintendo</td>\n      <td>Nintendo EAD</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1985.0</td>\n      <td>NaN</td>\n      <td>http://www.vgchartz.com/game/6455/super-mario-...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>/games/boxart/8972270ccc.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Mario Kart Wii</td>\n      <td>mario-kart-wii</td>\n      <td>Racing</td>\n      <td>E</td>\n      <td>Wii</td>\n      <td>Nintendo</td>\n      <td>Nintendo EAD</td>\n      <td>NaN</td>\n      <td>8.2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2008.0</td>\n      <td>11th Apr 18</td>\n      <td>http://www.vgchartz.com/game/6968/mario-kart-w...</td>\n      <td>1</td>\n      <td>8.7</td>\n      <td>/games/boxart/full_8932480AmericaFrontccc.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>PlayerUnknown's Battlegrounds</td>\n      <td>playerunknowns-battlegrounds</td>\n      <td>Shooter</td>\n      <td>NaN</td>\n      <td>PC</td>\n      <td>PUBG Corporation</td>\n      <td>PUBG Corporation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017.0</td>\n      <td>13th Nov 18</td>\n      <td>http://www.vgchartz.com/game/215988/playerunkn...</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>/games/boxart/full_8052843AmericaFrontccc.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Wii Sports Resort</td>\n      <td>wii-sports-resort</td>\n      <td>Sports</td>\n      <td>E</td>\n      <td>Wii</td>\n      <td>Nintendo</td>\n      <td>Nintendo EAD</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009.0</td>\n      <td>NaN</td>\n      <td>http://www.vgchartz.com/game/24656/wii-sports-...</td>\n      <td>1</td>\n      <td>8.8</td>\n      <td>/games/boxart/full_7295041AmericaFrontccc.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "import locale\n",
    "\n",
    "locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' )\n",
    "df = pd.read_csv(\"vgsales-12-4-2019.csv\")\n",
    "additional = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   number                            game  release_date  price  \\\n0       1                     Half-Life 2  Nov 16, 2004   9.99   \n1       3          Counter-Strike: Source   Nov 1, 2004   9.99   \n2      21  Counter-Strike: Condition Zero   Mar 1, 2004   9.99   \n3      47         Half-Life 2: Deathmatch   Nov 1, 2004   4.99   \n4      36               Half-Life: Source   Jun 1, 2004   9.99   \n\n                     owners developer publisher  average_playtime  \\\n0  10,000,000 .. 20,000,000     Valve     Valve             110.0   \n1  10,000,000 .. 20,000,000     Valve     Valve             236.0   \n2  10,000,000 .. 20,000,000     Valve     Valve              10.0   \n3   5,000,000 .. 10,000,000     Valve     Valve               0.0   \n4    2,000,000 .. 5,000,000     Valve     Valve               0.0   \n\n   median_playtime  metascore  \n0             66.0       96.0  \n1            128.0       88.0  \n2              3.0       65.0  \n3              0.0        NaN  \n4              0.0        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>game</th>\n      <th>release_date</th>\n      <th>price</th>\n      <th>owners</th>\n      <th>developer</th>\n      <th>publisher</th>\n      <th>average_playtime</th>\n      <th>median_playtime</th>\n      <th>metascore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Half-Life 2</td>\n      <td>Nov 16, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>110.0</td>\n      <td>66.0</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Counter-Strike: Source</td>\n      <td>Nov 1, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>236.0</td>\n      <td>128.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>Counter-Strike: Condition Zero</td>\n      <td>Mar 1, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>65.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47</td>\n      <td>Half-Life 2: Deathmatch</td>\n      <td>Nov 1, 2004</td>\n      <td>4.99</td>\n      <td>5,000,000 .. 10,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36</td>\n      <td>Half-Life: Source</td>\n      <td>Jun 1, 2004</td>\n      <td>9.99</td>\n      <td>2,000,000 .. 5,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Clean the additional dataset**\n",
    "\n",
    "Let's process the additional dataset. First, we drop rows with NaN values in the columns \"owners\" and \"release_date\"\n",
    "because we do not want to have missing values in these columns, and reset the index of the dataframe. Next, we divide\n",
    "the values in the column \"metascore\" by 10 to make the unit (a float with one decimal place) match in both tables, and\n",
    "store the results in a new column \"Critic_Score\". To calculate the median of the range of owners, we convert the values\n",
    "in the column \"owners\" to string, then iterate through the dataframe to split the string and convert the results to integers,\n",
    "finally we calculate the result (in millions). In the same loop, we also extract the value of year from the column \"release_date\".\n",
    " Note that there are NaN values in the column \"Critic_Score\" but we do not drop them because our main goal is to get more values\n",
    " for \"Global_Sales\". After renaming the columns that we will use to merge the datasets\n",
    " (by copying to new columns and dropping the original columns), we finish processing the additional dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   Critic_Score  Year                            Name Developer Global_Sales\n0           9.6  2004                     Half-Life 2     Valve            5\n1           8.8  2004          Counter-Strike: Source     Valve            5\n2           6.5  2004  Counter-Strike: Condition Zero     Valve            5\n3           NaN  2004         Half-Life 2: Deathmatch     Valve          2.5\n4           NaN  2004               Half-Life: Source     Valve          1.5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Critic_Score</th>\n      <th>Year</th>\n      <th>Name</th>\n      <th>Developer</th>\n      <th>Global_Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.6</td>\n      <td>2004</td>\n      <td>Half-Life 2</td>\n      <td>Valve</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.8</td>\n      <td>2004</td>\n      <td>Counter-Strike: Source</td>\n      <td>Valve</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6.5</td>\n      <td>2004</td>\n      <td>Counter-Strike: Condition Zero</td>\n      <td>Valve</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>2004</td>\n      <td>Half-Life 2: Deathmatch</td>\n      <td>Valve</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>2004</td>\n      <td>Half-Life: Source</td>\n      <td>Valve</td>\n      <td>1.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional = additional.dropna(subset = ['owners', 'release_date'])\n",
    "additional = additional.reset_index(drop = True)\n",
    "additional['Critic_Score'] = additional['metascore']/10\n",
    "additional['Year'] = additional['release_date']\n",
    "additional['owners'] = additional['owners'].astype(str)\n",
    "# calculate median of owners and extract value of year\n",
    "for i in range(len(additional)):\n",
    "    str(additional.loc[i, 'owners'])\n",
    "    nums = additional.loc[i, 'owners'].split('\\xa0..\\xa0')\n",
    "    additional.loc[i, 'owners'] = float((locale.atoi(nums[1]) - locale.atoi(nums[0])) / 2000000)\n",
    "    temp = additional.loc[i, 'Year'].split(', ')\n",
    "    if len(temp) != 2:\n",
    "        additional.loc[i, 'Year'] = np.nan\n",
    "    else:\n",
    "        additional.loc[i, 'Year'] = int(temp[1])\n",
    "\n",
    "additional = additional.dropna(subset = ['release_date'])\n",
    "# drop useless columns and rename columns\n",
    "additional = additional.drop(columns = ['number', 'price', 'average_playtime', 'median_playtime'])\n",
    "additional['Name'] = additional['game']\n",
    "additional['Developer'] = additional['developer']\n",
    "additional['Global_Sales'] = additional['owners']\n",
    "additional = additional.drop(columns=['metascore', 'release_date', 'publisher', 'game', 'developer', 'owners'])\n",
    "additional.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Merge the main dataset and the additional dataset**\n",
    "\n",
    "Before merging the two datasets, we drop rows having missing values in the column \"Year\" as we will use this column\n",
    "and the column \"Name\" in merging. Then we drop columns we will not use in data visualization and data analysis, which\n",
    "are 'Rank', 'basename', 'Total_Shipped', 'Platform', 'Publisher', 'VGChartz_Score', 'Last_Update', 'url', 'status',\n",
    "'Vgchartzscore', 'img_url', 'User_Score'.\n",
    "\n",
    "The type of join we choose is left join, because we do not want to add excessive records from the additional dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                            Name     Genre ESRB_Rating         Developer  \\\n0                     Wii Sports    Sports           E      Nintendo EAD   \n1              Super Mario Bros.  Platform         NaN      Nintendo EAD   \n2                 Mario Kart Wii    Racing           E      Nintendo EAD   \n3  PlayerUnknown's Battlegrounds   Shooter         NaN  PUBG Corporation   \n4              Wii Sports Resort    Sports           E      Nintendo EAD   \n\n   Critic_Score  Global_Sales  NA_Sales  PAL_Sales  JP_Sales  Other_Sales  \\\n0           7.7           NaN       NaN        NaN       NaN          NaN   \n1          10.0           NaN       NaN        NaN       NaN          NaN   \n2           8.2           NaN       NaN        NaN       NaN          NaN   \n3           NaN           NaN       NaN        NaN       NaN          NaN   \n4           8.0           NaN       NaN        NaN       NaN          NaN   \n\n   Year  \n0  2006  \n1  1985  \n2  2008  \n3  2017  \n4  2009  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Genre</th>\n      <th>ESRB_Rating</th>\n      <th>Developer</th>\n      <th>Critic_Score</th>\n      <th>Global_Sales</th>\n      <th>NA_Sales</th>\n      <th>PAL_Sales</th>\n      <th>JP_Sales</th>\n      <th>Other_Sales</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wii Sports</td>\n      <td>Sports</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>7.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Super Mario Bros.</td>\n      <td>Platform</td>\n      <td>NaN</td>\n      <td>Nintendo EAD</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1985</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mario Kart Wii</td>\n      <td>Racing</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>8.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PlayerUnknown's Battlegrounds</td>\n      <td>Shooter</td>\n      <td>NaN</td>\n      <td>PUBG Corporation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wii Sports Resort</td>\n      <td>Sports</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset = ['Year'])\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "df = df.drop(columns=['Rank', 'basename', 'Total_Shipped', 'Platform', 'Publisher', 'VGChartz_Score',\n",
    "                      'Last_Update', 'url', 'status', 'Vgchartzscore', 'img_url',  'User_Score'])\n",
    "# left join on 'Name', 'Year'\n",
    "pd.merge(df, additional, on = ['Name', 'Year'] , how = 'left')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Process the merged dataset**\n",
    "\n",
    "First we drop rows with missing values in the columns \"Developer\" and \"Genre\", and reset the index.\n",
    "It is obvious to predict sales as numerical data but we have the accuracy concern(we will see accuracy in the **Result Analysis and Demonstration** section)\n",
    "since the data may not demonstrate a strong linear trend. Therefore, we hope to predict it as categorical data: sale score is divided into 4 categories.\n",
    "Games in \">10\" category are expected to sell so greate that its name will left in history -- Grand Theft Auto, Pokemon, Call of duty and etc. You name it.\n",
    "Games in \"5-10\" category are sold less than the top ones, but they are still great games. \"5-1\" games are good games. there are still large amount of customer want to\n",
    "put them into their gaming library. The rest of games can be put into \"1-0\" categories. We respect the efforts that game developers put into them but they are relatively\n",
    "niche.\n",
    "\n",
    "For data analysis, we need to convert categorical variable to numerical variable. We choose to use label encoding on\n",
    "the three categories, \"Genre\", \"ESRB_Rating\" and \"Developer\" because it is easier to process numerical values in data\n",
    "analysis than processing string values. Since the total number of developers is large and we will use \"Genre\"\n",
    "in data visualization, we will process \"Developer\" and \"Genre\" later. To create the dataframe for data analysis,\n",
    " we need to drop columns that we will not use, which are 'Name', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Critic_Score'.\n",
    "  Also, we will normalize the numerical values in the columns \"Global_Sales\" and \"NA_Sales\" by using the sklearn.preprocessing module."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Developer', 'Genre'])\n",
    "df = df.reset_index(drop = True)\n",
    "df['Sales_Ranking'] = df['Global_Sales']\n",
    "# get values for the column 'Sales_Ranking'\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'Developer'] = str(df.loc[i, 'Developer'])\n",
    "    if df.loc[i, 'Sales_Ranking'] >= 10:\n",
    "        df.loc[i, 'Sales_Ranking'] = 4\n",
    "    elif df.loc[i, 'Sales_Ranking'] >= 5 and df.loc[i, 'Sales_Ranking'] < 10:\n",
    "        df.loc[i, 'Sales_Ranking'] = 3\n",
    "    elif df.loc[i, 'Sales_Ranking'] >= 1 and df.loc[i, 'Sales_Ranking'] < 5:\n",
    "        df.loc[i, 'Sales_Ranking'] = 2\n",
    "    else:\n",
    "        df.loc[i, 'Sales_Ranking'] = 1\n",
    "\n",
    "le = LabelEncoder()\n",
    "# ohe = OneHotEncoder(handle_unknown = 'ignore')\n",
    "df['Sales_Ranking'] = df['Sales_Ranking'].astype(int)\n",
    "df = df.dropna(subset=['Global_Sales', 'ESRB_Rating'])\n",
    "df['ESRB_Rating'] = le.fit_transform(df['ESRB_Rating'])\n",
    "# df_temp = pd.DataFrame(ohe.fit_transform(df[['Genre']]).toarray())\n",
    "# df = df.join(df_temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Dataframe for data visualization**\n",
    "\n",
    "Now we create the dataframe for data visualization. We drop rows with NaN values in the columns \"Global_Sales\"\n",
    "and \"NA_Sales\" because these missing values can not be used in plotting the graphs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                          Name    Genre  ESRB_Rating       Developer  \\\n0           Grand Theft Auto V   Action            3  Rockstar North   \n1           Grand Theft Auto V   Action            3  Rockstar North   \n2  Grand Theft Auto: Vice City   Action            3  Rockstar North   \n3           Grand Theft Auto V   Action            3  Rockstar North   \n4    Call of Duty: Black Ops 3  Shooter            3        Treyarch   \n\n   Critic_Score  Global_Sales  NA_Sales  PAL_Sales  JP_Sales  Other_Sales  \\\n0           9.4         20.32      6.37       9.85      0.99         3.12   \n1           9.7         19.39      6.06       9.71      0.60         3.02   \n2           9.6         16.15      8.41       5.49      0.47         1.78   \n3           NaN         15.86      9.06       5.33      0.06         1.42   \n4           NaN         15.09      6.18       6.05      0.41         2.44   \n\n   Year  Sales_Ranking  \n0  2013              4  \n1  2014              4  \n2  2002              4  \n3  2013              4  \n4  2015              4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Genre</th>\n      <th>ESRB_Rating</th>\n      <th>Developer</th>\n      <th>Critic_Score</th>\n      <th>Global_Sales</th>\n      <th>NA_Sales</th>\n      <th>PAL_Sales</th>\n      <th>JP_Sales</th>\n      <th>Other_Sales</th>\n      <th>Year</th>\n      <th>Sales_Ranking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Grand Theft Auto V</td>\n      <td>Action</td>\n      <td>3</td>\n      <td>Rockstar North</td>\n      <td>9.4</td>\n      <td>20.32</td>\n      <td>6.37</td>\n      <td>9.85</td>\n      <td>0.99</td>\n      <td>3.12</td>\n      <td>2013</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Grand Theft Auto V</td>\n      <td>Action</td>\n      <td>3</td>\n      <td>Rockstar North</td>\n      <td>9.7</td>\n      <td>19.39</td>\n      <td>6.06</td>\n      <td>9.71</td>\n      <td>0.60</td>\n      <td>3.02</td>\n      <td>2014</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Grand Theft Auto: Vice City</td>\n      <td>Action</td>\n      <td>3</td>\n      <td>Rockstar North</td>\n      <td>9.6</td>\n      <td>16.15</td>\n      <td>8.41</td>\n      <td>5.49</td>\n      <td>0.47</td>\n      <td>1.78</td>\n      <td>2002</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Grand Theft Auto V</td>\n      <td>Action</td>\n      <td>3</td>\n      <td>Rockstar North</td>\n      <td>NaN</td>\n      <td>15.86</td>\n      <td>9.06</td>\n      <td>5.33</td>\n      <td>0.06</td>\n      <td>1.42</td>\n      <td>2013</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Call of Duty: Black Ops 3</td>\n      <td>Shooter</td>\n      <td>3</td>\n      <td>Treyarch</td>\n      <td>NaN</td>\n      <td>15.09</td>\n      <td>6.18</td>\n      <td>6.05</td>\n      <td>0.41</td>\n      <td>2.44</td>\n      <td>2015</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop = True)\n",
    "df = df[df['Global_Sales'] != 0.0]\n",
    "df_for_visualization = df.dropna(subset = ['Global_Sales', 'NA_Sales'])\n",
    "df_for_visualization = df_for_visualization.reset_index(drop = True)\n",
    "df_for_visualization.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Dataframe for data analysis**\n",
    "\n",
    "To create the dataframe for data analysis, we need to drop columns that we will not use,\n",
    "which are 'Name', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Critic_Score'. Also, we will normalize\n",
    "the numerical values in the columns \"Global_Sales\" and \"NA_Sales\" by using the sklearn.preprocessing module."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "       Genre  ESRB_Rating  Developer  NA_Sales  Year  Global_Sales  \\\n3153       7            0       1772  0.017418  2007      0.024126   \n7407      17            0        937  0.010246  2002      0.005908   \n10654     15            0        695  0.002049  2002      0.000985   \n9829       0            3       1558  0.004098  2007      0.001969   \n7877       0            5        331  0.010246  2016      0.005416   \n...      ...          ...        ...       ...   ...           ...   \n3049       0            3       1412  0.009221  2005      0.025111   \n5429       7            3       1807  0.012295  2002      0.011324   \n7101       5            1       1271  0.013320  2007      0.006893   \n11286      7            2        125  0.001025  2005      0.000000   \n3721       0            1          3  0.032787  2009      0.020187   \n\n       Sales_Ranking  \n3153               1  \n7407               1  \n10654              1  \n9829               1  \n7877               1  \n...              ...  \n3049               1  \n5429               1  \n7101               1  \n11286              1  \n3721               1  \n\n[11348 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Genre</th>\n      <th>ESRB_Rating</th>\n      <th>Developer</th>\n      <th>NA_Sales</th>\n      <th>Year</th>\n      <th>Global_Sales</th>\n      <th>Sales_Ranking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3153</th>\n      <td>7</td>\n      <td>0</td>\n      <td>1772</td>\n      <td>0.017418</td>\n      <td>2007</td>\n      <td>0.024126</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7407</th>\n      <td>17</td>\n      <td>0</td>\n      <td>937</td>\n      <td>0.010246</td>\n      <td>2002</td>\n      <td>0.005908</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10654</th>\n      <td>15</td>\n      <td>0</td>\n      <td>695</td>\n      <td>0.002049</td>\n      <td>2002</td>\n      <td>0.000985</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9829</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1558</td>\n      <td>0.004098</td>\n      <td>2007</td>\n      <td>0.001969</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7877</th>\n      <td>0</td>\n      <td>5</td>\n      <td>331</td>\n      <td>0.010246</td>\n      <td>2016</td>\n      <td>0.005416</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3049</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1412</td>\n      <td>0.009221</td>\n      <td>2005</td>\n      <td>0.025111</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5429</th>\n      <td>7</td>\n      <td>3</td>\n      <td>1807</td>\n      <td>0.012295</td>\n      <td>2002</td>\n      <td>0.011324</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7101</th>\n      <td>5</td>\n      <td>1</td>\n      <td>1271</td>\n      <td>0.013320</td>\n      <td>2007</td>\n      <td>0.006893</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11286</th>\n      <td>7</td>\n      <td>2</td>\n      <td>125</td>\n      <td>0.001025</td>\n      <td>2005</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3721</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.032787</td>\n      <td>2009</td>\n      <td>0.020187</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>11348 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training = df.drop(columns = ['Name', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Critic_Score'])\n",
    "df_for_training = df_for_training.dropna(subset = ['NA_Sales'])\n",
    "temp_df = df_for_training.drop(columns=['Genre', 'ESRB_Rating', 'Developer', 'Year', 'Sales_Ranking'])\n",
    "# create a temp dataframe for normalization of numerical values\n",
    "x = temp_df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "temp_df = pd.DataFrame(x_scaled)\n",
    "# copy normalized values into the training dataframe\n",
    "df_for_training['Global_Sales'] = temp_df[0]\n",
    "df_for_training['NA_Sales'] = temp_df[1]\n",
    "df_for_training = df_for_training.dropna(subset = ['Global_Sales', 'NA_Sales'])\n",
    "df_for_training = df_for_training.reset_index(drop = True)\n",
    "# apply label encoding on 'Genre' and 'Developer'\n",
    "df_for_training['Genre'] = le.fit_transform(df_for_training['Genre'])\n",
    "df_for_training['Developer'] = le.fit_transform(df_for_training['Developer'])\n",
    "# Shuffle and reorder the dataframe\n",
    "df_for_training = df_for_training.sample(frac=1)[['Genre','ESRB_Rating','Developer','NA_Sales','Year','Global_Sales','Sales_Ranking']]\n",
    "df_for_training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.b Data Analysis and Visualization' <a name=\"data-ana-vis\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Machine Learning Model <a name=\"ml-model\"></a>\n",
    "In this section, we are going to implement several models and predict global sales. In the world of machine learning, people\n",
    "can split datas into two groups: numerical data and categorical data. Numerical data is everything that represented by numbers (integer\n",
    "and floating point). It's continuous. Categorical data, however, is discrete. Different models will be used to predict these two type of data.\n",
    "\n",
    "### 5.a What and Why <a name=\"what-why\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want to use *multiple linear regression* for predicting numerical sale number. The reason is that we intend to investigate\n",
    "how strong the relationship is between many independent variables (in this case, critic score, developers and other variables) and\n",
    "one dependent variable -- sale score. We made several assumptions for using multiple linear regression.\n",
    " - Homogeneity of Variance: the size of the error in our prediction doesn't change a lot\n",
    " - Independence of Observations: each game is independent of others.\n",
    " - Linearity: the line of best fit through the data point is a straight line."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Several models will be used for the prediction of categorical sale number: *Random forest*, *k-nearest neighbors* (KNN) and\n",
    "*Support vector machine*(SVM)\n",
    "\n",
    "Single decision tree suffers from a high variance, which makes them less accurate than other models. However, random forest fixes\n",
    "this problem. Benefits of using random forests:\n",
    " -  Bagging and bootstrap reduce the output variance\n",
    " -  Able to handle large dataset with high dimensionality (which is our datset)\n",
    "\n",
    "k-nearest neightbors, as one of the most famous classifications algorithm, surely have many positive sides:\n",
    " - No training period\n",
    " - Easily to add new data\n",
    " - Easy to implement\n",
    "\n",
    "Here is the advantages of choosing support vector machine as one of our algorithem.\n",
    " -  Effective in high dimensional spaces\n",
    " -  Use a subset of training set in the decision function and, therefore, prevent overfitting\n",
    " -  Memory efficient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.b Training <a name=\"training\"></a>\n",
    "**Multiple Linear Regression**\n",
    "\n",
    "We will use sklearn library for most of our training task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "\n",
    "# build model for numerical predictors\n",
    "muti_linear_regression = linear_model.LinearRegression(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explanation:\n",
    "\n",
    "This is a very simple and straight-forward model with n_jobs = -1, which means we want to use all available CPU cores for efficiency purpose\n",
    "\n",
    "**Categorical Model**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# build model for categorical predictors\n",
    "random_forest = RandomForestClassifier(n_estimators = 1000, random_state=42,max_depth=4,n_jobs = -1)\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "svm = sklearn.svm.LinearSVC(max_iter=2000,dual=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explanation:\n",
    "\n",
    "To determine the number of trees (n_estimators in the function), we theoretically want as many trees as possible but the\n",
    "margin of accuracy of getting more than 1000 trees become neglectable. random_state will increase the randomness when the algorithm is\n",
    "bootstrapping.It is suggested that the maximum depth of the tree is sqrt(number of features), and also the\n",
    "more depth of a tree, the better it perform with diminishing returns. I will just choose 4 and the benefit of more than 4 is too small. The number of jobs indicates how many\n",
    "threads that are working in parallel.\n",
    "\n",
    "As for kNN, to determine the number of neighbors, I did several experiments. It turns out that n_neightbors = 5 can generate best output. Too small n_neightbor will result in\n",
    "unstable decision boundaries will too large will make the decision boundaries unclear.\n",
    "\n",
    "SVM is little bit intriguing. There are two options for us to set the \"decision_function_shape\". One is \"ovo\", which stands for one-verses-one, and the other option is called one-vs-the-rest.\n",
    "One-verse-one compare each classcifier with the predict value one by one while the one verse the rest option treats the x as a group and compare it with the y. In our case, we consider all the regressor\n",
    "as a group. The reason why we set max_iter to 2000 is that it will not converge at default number of iterations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Assign first several columns as X and last two columns as ground truth\n",
    "X = df_for_training.iloc[:, 0:5]\n",
    "y_categorical = df_for_training[['Sales_Ranking']].to_numpy().flatten()\n",
    "y_numerical = df_for_training[['Global_Sales']].to_numpy().flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score for linear regression is  0.8329380526739645\n",
      "The standard error of the score is  0.044375140974953854\n"
     ]
    }
   ],
   "source": [
    "# numerical model\n",
    "# 10-fold cross validation for multi-linear regression:\n",
    "linear_score = []\n",
    "X = X.to_numpy()\n",
    "for train_index, test_index in model_selection.KFold(n_splits=10).split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_numerical[train_index], y_numerical[test_index]\n",
    "    model = muti_linear_regression.fit(X_train,y_train)\n",
    "    score = model.score(X_test,y_test)\n",
    "    linear_score.append(score)\n",
    "print('The average score for linear regression is ',np.average(linear_score))\n",
    "print(\"The standard error of the score is \", np.std(linear_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score for Random Forest is  0.9443951860398265\n",
      "The standard error of the score is  0.006578077092256287\n",
      "The average score for kNN is  0.8731059988035025\n",
      "The standard error of the score is  0.005475860780734276\n",
      "The average score for SVM is  0.8992760413024732\n",
      "The standard error of the score is  0.01149247828173759\n"
     ]
    }
   ],
   "source": [
    "# categorical model\n",
    "# Implement 10-fold cross validation\n",
    "rfr_score = model_selection.cross_val_score(random_forest, X, y_categorical, cv = 10)\n",
    "print(\"The average score for Random Forest is \", np.average(rfr_score))\n",
    "print(\"The standard error of the score is \", np.std(rfr_score))\n",
    "knn_score = model_selection.cross_val_score(knn, X, y_categorical, cv = 10)\n",
    "print(\"The average score for kNN is \", np.average(knn_score))\n",
    "print(\"The standard error of the score is \", np.std(knn_score))\n",
    "svm_score = model_selection.cross_val_score(svm,X, y_categorical, cv = 10)\n",
    "print(\"The average score for SVM is \", np.average(svm_score))\n",
    "print(\"The standard error of the score is \", np.std(svm_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.c Result Anlysis and Demonstration <a name=\"result-and-demon\"></a>\n",
    "Below is the bar graph of accuracy score for different models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "models = ['linear_reg', 'radom forest', 'knn', 'svm']\n",
    "scores = [linear_score,rfr_score, knn_score,svm_score]\n",
    "accuracy = np.average(scores,axis=1)\n",
    "std = np.std(scores,axis=1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(models,accuracy,align = 'center',yerr = std, capsize=20)\n",
    "ax.set_xticks(models)\n",
    "ax.set_title('Accuracy of Four Models For Game Sale Prediction')\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel('Accuracy Score')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random forest model has the best accuracy score and I think bagging and bootstrap could be the reason why it outperformed other models.\n",
    "Also, the prediction for categorical variable generally better than the numerical prediction becuase, intuitively, predicting a category is\n",
    "easier than a specific number.\n",
    "\n",
    "Since we are interested in the difference between two variables for the same subject, we are going to perform paired-t test for the predicted value and the ground truth to see\n",
    "the statistical difference between them. Our null hypothesis would be the average difference between the predicted value and ground truth is 0 and alternative hypothesis is the\n",
    "average difference is not 0. We choose alpha value = 0.05"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired t-test for  multi-linear regression has the following result\n",
      "test statistics = 0.0 \n",
      "p value = 1.0\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "muti_linear_regression.fit(X,y_categorical)\n",
    "pred_y = muti_linear_regression.predict(X)\n",
    "(statistics, pvalue) = stats.ttest_rel(y_categorical, pred_y)\n",
    "print(\"paired t-test for  multi-linear regression has the following result\")\n",
    "print(f'test statistics = {np.round(statistics,3)} \\np value = {np.round(pvalue,3)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired t-test for random forest  has the following result\n",
      "test statistics = 7.85 \n",
      "p value = 0.0\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(X,y_categorical)\n",
    "pred_y = random_forest.predict(X)\n",
    "(statistics, pvalue) = stats.ttest_rel(y_categorical, pred_y)\n",
    "print(\"paired t-test for random forest  has the following result\")\n",
    "print(f'test statistics = {np.round(statistics,3)} \\np value = {np.round(pvalue,3)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired t-test for k-nearest neightbor has the following result\n",
      "test statistics = 22.912 \n",
      "p value = 0.0\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X,y_categorical)\n",
    "pred_y = knn.predict(X)\n",
    "(statistics, pvalue) = stats.ttest_rel(y_categorical, pred_y)\n",
    "print(\"paired t-test for k-nearest neightbor has the following result\")\n",
    "print(f'test statistics = {np.round(statistics,3)} \\np value = {np.round(pvalue,3)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired t-test for support vector machine has the following result\n",
      "test statistics = 39.691 \n",
      "p value = 0.0\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X,y_categorical)\n",
    "pred_y = svm.predict(X)\n",
    "(statistics, pvalue) = stats.ttest_rel(y_categorical, pred_y)\n",
    "print(\"paired t-test for support vector machine has the following result\")\n",
    "print(f'test statistics = {np.round(statistics,3)} \\np value = {np.round(pvalue,3)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From above result, it is interesting to see that we failed reject null hypothesis (i.e. there is no difference between\n",
    "the predicted value and ground truth for multi-linear regression paired-t test) but reject the null hypothesis (that is, there IS a difference)\n",
    "for the rest of three paired-t test. However, according to the accuracy score, random forest model achieved the highest. Why does this happen?\n",
    "\n",
    "According the formula that calculate t-value, we need to find the standard deviation of the difference between two groups. This standard deviation doesn't\n",
    "make sense when it comes to category. You can think it as using l2 loss (mean squared error) instead of cross-entropy loss for categorical problem. Therefore,\n",
    "we'd better directly use accuracy score for model-model comparison."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Future Application <a name=\"future-app\"></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Reference and External Link <a name=\"ref-and-extlink\"></a>\n",
    "#### Gaming industry statistics\n",
    " - https://www.statista.com/statistics/292056/video-game-market-value-worldwide/\n",
    " - https://www.statista.com/statistics/552623/number-games-released-steam/\n",
    "\n",
    "#### Want to to know more about multiple linear regression?\n",
    " - https://www.scribbr.com/statistics/multiple-linear-regression/\n",
    " - https://en.wikipedia.org/wiki/Linear_regression\n",
    " - https://towardsdatascience.com/understanding-multiple-regression-249b16bde83e\n",
    "\n",
    "#### Extend materials for support vector machine, Knn, random forest\n",
    " - https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47\n",
    " - https://www.youtube.com/watch?v=1NxnPkZM9bc\n",
    " - https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n",
    " - https://scikit-learn.org/stable/modules/svm.html\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "#### paired-t test reading:\n",
    " - https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/SAS/SAS4-OneSampleTtest/SAS4-OneSampleTtest7.html"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7738021d",
   "language": "python",
   "display_name": "PyCharm (cmsc320fall2020)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}