{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Siyuan \"Kevin\" Peng, Yuanzhe \"Siris\" Zheng, Yanlin \"Jacky\" Liu\n",
    "![Image of Yaktocat](https://cdn.mos.cms.futurecdn.net/rLh7Dh7EKo8F6zmDtXYp8W.jpg)\n",
    "# Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Install packages](#install-pkg)\n",
    "3. [Data Dowloading](#data-download)\n",
    "4. [Preprocessing](#preprocessing)<br>\n",
    "    a. [Load and Clean Dataset](#load-and-clean)<br>\n",
    "    b. [Data Analysis and Visualization](#data-ana-vis)\n",
    "5. [Machine Learning Model](#ml-model)<br>\n",
    "    a. [What and Why](#what-why)<br>\n",
    "    b. [Training](#training)<br>\n",
    "    c. [Result Anlysis and Demonstration](#result-ana-demon)\n",
    "6. [Future Application](#future-app)\n",
    "7. [Reference and External Link](#ref-and-extlink)\n",
    "\n",
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Packages <a name=\"install-pkg\"></a>\n",
    "```\n",
    "pip install kaggle numpy matplotlib pandas sklearn\n",
    "```\n",
    "or use [environment.yml](https://github.com/syKevinPeng/game_sale_analysis/blob/main/environment.yml) to install packages in Conda environment\n",
    "```\n",
    "conda env update -f environment.yml\n",
    "```\n",
    "## 3. Data Downloading <a name=\"data-download\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-games-sales-2019.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "# remember to put kaggle.json to your C:/username/.kaggle\n",
    "!kaggle datasets download -d ashaheedq/video-games-sales-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "or directly download from kaggle webpage: [https://www.kaggle.com/ashaheedq/video-games-sales-2019](https://www.kaggle.com/ashaheedq/video-games-sales-2019)_\n",
    "## 4. Preprocessing <a name=\"preprocessing\"></a>\n",
    "### 4.a. Load and Clean Data <a name=\"load-and-clean\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   number                            game  release_date  price  \\\n0       1                     Half-Life 2  Nov 16, 2004   9.99   \n1       3          Counter-Strike: Source   Nov 1, 2004   9.99   \n2      21  Counter-Strike: Condition Zero   Mar 1, 2004   9.99   \n3      47         Half-Life 2: Deathmatch   Nov 1, 2004   4.99   \n4      36               Half-Life: Source   Jun 1, 2004   9.99   \n\n                     owners developer publisher  average_playtime  \\\n0  10,000,000 .. 20,000,000     Valve     Valve             110.0   \n1  10,000,000 .. 20,000,000     Valve     Valve             236.0   \n2  10,000,000 .. 20,000,000     Valve     Valve              10.0   \n3   5,000,000 .. 10,000,000     Valve     Valve               0.0   \n4    2,000,000 .. 5,000,000     Valve     Valve               0.0   \n\n   median_playtime  metascore  \n0             66.0       96.0  \n1            128.0       88.0  \n2              3.0       65.0  \n3              0.0        NaN  \n4              0.0        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>game</th>\n      <th>release_date</th>\n      <th>price</th>\n      <th>owners</th>\n      <th>developer</th>\n      <th>publisher</th>\n      <th>average_playtime</th>\n      <th>median_playtime</th>\n      <th>metascore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Half-Life 2</td>\n      <td>Nov 16, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>110.0</td>\n      <td>66.0</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Counter-Strike: Source</td>\n      <td>Nov 1, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>236.0</td>\n      <td>128.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>Counter-Strike: Condition Zero</td>\n      <td>Mar 1, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>65.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47</td>\n      <td>Half-Life 2: Deathmatch</td>\n      <td>Nov 1, 2004</td>\n      <td>4.99</td>\n      <td>5,000,000 .. 10,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36</td>\n      <td>Half-Life: Source</td>\n      <td>Jun 1, 2004</td>\n      <td>9.99</td>\n      <td>2,000,000 .. 5,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "import locale\n",
    "\n",
    "locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' ) \n",
    "df = pd.read_csv(\"vgsales-12-4-2019.csv\")\n",
    "additional = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv\")\n",
    "additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                             game  release_date owners developer publisher  \\\n0                     Half-Life 2  Nov 16, 2004      5     Valve     Valve   \n1          Counter-Strike: Source   Nov 1, 2004      5     Valve     Valve   \n2  Counter-Strike: Condition Zero   Mar 1, 2004      5     Valve     Valve   \n3         Half-Life 2: Deathmatch   Nov 1, 2004    2.5     Valve     Valve   \n4               Half-Life: Source   Jun 1, 2004    1.5     Valve     Valve   \n\n   metascore  Critic_Score  Year  \n0       96.0           9.6  2004  \n1       88.0           8.8  2004  \n2       65.0           6.5  2004  \n3        NaN           NaN  2004  \n4        NaN           NaN  2004  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game</th>\n      <th>release_date</th>\n      <th>owners</th>\n      <th>developer</th>\n      <th>publisher</th>\n      <th>metascore</th>\n      <th>Critic_Score</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Half-Life 2</td>\n      <td>Nov 16, 2004</td>\n      <td>5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>96.0</td>\n      <td>9.6</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Counter-Strike: Source</td>\n      <td>Nov 1, 2004</td>\n      <td>5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>88.0</td>\n      <td>8.8</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Counter-Strike: Condition Zero</td>\n      <td>Mar 1, 2004</td>\n      <td>5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>65.0</td>\n      <td>6.5</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Half-Life 2: Deathmatch</td>\n      <td>Nov 1, 2004</td>\n      <td>2.5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Half-Life: Source</td>\n      <td>Jun 1, 2004</td>\n      <td>1.5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional = additional.dropna(subset = ['owners', 'release_date'])\n",
    "additional = additional.reset_index(drop = True)\n",
    "additional['Critic_Score'] = additional['metascore']/10\n",
    "additional['Year'] = additional['release_date']\n",
    "additional['owners'] = additional['owners'].astype(str)\n",
    "for i in range(len(additional)):\n",
    "    str(additional.loc[i, 'owners'])\n",
    "    nums = additional.loc[i, 'owners'].split('\\xa0..\\xa0')\n",
    "#     print(nums)\n",
    "    additional.loc[i, 'owners'] = float((locale.atoi(nums[1]) - locale.atoi(nums[0])) / 2000000)\n",
    "#     print(additional.loc[i, 'owners'])\n",
    "    temp = additional.loc[i, 'Year'].split(', ')\n",
    "    if len(temp) != 2:\n",
    "        additional.loc[i, 'Year'] = np.nan\n",
    "    else:\n",
    "        additional.loc[i, 'Year'] = int(temp[1])\n",
    "#     print(additional.loc[i, 'Year'].split(', ')[1])\n",
    "additional = additional.dropna(subset = ['release_date'])\n",
    "additional = additional.drop(columns = ['number', 'price', 'average_playtime', 'median_playtime'])\n",
    "additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                            Name     Genre ESRB_Rating         Developer  \\\n0                     Wii Sports    Sports           E      Nintendo EAD   \n1              Super Mario Bros.  Platform         NaN      Nintendo EAD   \n2                 Mario Kart Wii    Racing           E      Nintendo EAD   \n3  PlayerUnknown's Battlegrounds   Shooter         NaN  PUBG Corporation   \n4              Wii Sports Resort    Sports           E      Nintendo EAD   \n\n   Critic_Score  Global_Sales  NA_Sales  PAL_Sales  JP_Sales  Other_Sales  \\\n0           7.7           NaN       NaN        NaN       NaN          NaN   \n1          10.0           NaN       NaN        NaN       NaN          NaN   \n2           8.2           NaN       NaN        NaN       NaN          NaN   \n3           NaN           NaN       NaN        NaN       NaN          NaN   \n4           8.0           NaN       NaN        NaN       NaN          NaN   \n\n   Year  \n0  2006  \n1  1985  \n2  2008  \n3  2017  \n4  2009  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Genre</th>\n      <th>ESRB_Rating</th>\n      <th>Developer</th>\n      <th>Critic_Score</th>\n      <th>Global_Sales</th>\n      <th>NA_Sales</th>\n      <th>PAL_Sales</th>\n      <th>JP_Sales</th>\n      <th>Other_Sales</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wii Sports</td>\n      <td>Sports</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>7.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Super Mario Bros.</td>\n      <td>Platform</td>\n      <td>NaN</td>\n      <td>Nintendo EAD</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1985</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mario Kart Wii</td>\n      <td>Racing</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>8.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PlayerUnknown's Battlegrounds</td>\n      <td>Shooter</td>\n      <td>NaN</td>\n      <td>PUBG Corporation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wii Sports Resort</td>\n      <td>Sports</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional['Name'] = additional['game']\n",
    "additional['Developer'] = additional['developer']\n",
    "additional['Global_Sales'] = additional['owners']\n",
    "df = df.dropna(subset = ['Year'])\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "additional = additional.drop(columns=['metascore', 'release_date', 'publisher', 'game', 'developer', 'owners'])\n",
    "df = df.drop(columns=['Rank', 'basename', 'Total_Shipped', 'Platform', 'Publisher', 'VGChartz_Score', \n",
    "                      'Last_Update', 'url', 'status', 'Vgchartzscore', 'img_url',  'User_Score'])\n",
    "pd.merge(df, additional, on = ['Name', 'Year'] , how = 'left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Developer', 'Genre'])\n",
    "df = df.reset_index(drop = True)\n",
    "df['Sales_Ranking'] = df['Global_Sales']\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'Developer'] = str(df.loc[i, 'Developer'])\n",
    "    if df.loc[i, 'Sales_Ranking'] >= 10:\n",
    "        df.loc[i, 'Sales_Ranking'] = 4\n",
    "    elif df.loc[i, 'Sales_Ranking'] >= 5 and df.loc[i, 'Sales_Ranking'] < 10:\n",
    "        df.loc[i, 'Sales_Ranking'] = 3\n",
    "    elif df.loc[i, 'Sales_Ranking'] >= 1 and df.loc[i, 'Sales_Ranking'] < 5:\n",
    "        df.loc[i, 'Sales_Ranking'] = 2\n",
    "    else:\n",
    "        df.loc[i, 'Sales_Ranking'] = 1\n",
    "le = LabelEncoder()\n",
    "# ohe = OneHotEncoder(handle_unknown = 'ignore')\n",
    "df['Sales_Ranking'] = df['Sales_Ranking'].astype(int)\n",
    "# df['Developer'] = le.fit_transform(df['Developer'])\n",
    "df['Genre'] = le.fit_transform(df['Genre'])\n",
    "df = df.dropna(subset=['Global_Sales', 'ESRB_Rating'])\n",
    "df['ESRB_Rating'] = le.fit_transform(df['ESRB_Rating'])\n",
    "# df_temp = pd.DataFrame(ohe.fit_transform(df[['Genre']]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df.join(df_temp)\n",
    "\n",
    "df = df.reset_index(drop = True)\n",
    "df = df[df['Global_Sales'] != 0.0]\n",
    "df_for_visualization = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training = df\n",
    "df_for_training = df.drop(columns = ['Name', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Critic_Score'])\n",
    "df_for_training = df_for_training.dropna(subset = ['NA_Sales'])\n",
    "temp_df = df_for_training.drop(columns=['Genre', 'ESRB_Rating', 'Developer', 'Year', 'Sales_Ranking'])\n",
    "\n",
    "x = temp_df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "temp_df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Genre  ESRB_Rating  Developer  NA_Sales  Year  Global_Sales  \\\n9592      12            5       1355  0.005123  2002      0.002954   \n1533      15            5       1570  0.047131  2006      0.047267   \n2003       0            3        788  0.024590  2017      0.037912   \n2400      13            5        926  0.017418  2005      0.032004   \n8433      16            0       1763  0.010246  2009      0.004924   \n...      ...          ...        ...       ...   ...           ...   \n2032      17            0         57  0.038934  2002      0.037420   \n10905     10            0        126  0.003074  2004      0.001477   \n1121      17            0        492  0.013320  2012      0.061054   \n6280       1            1        181  0.011270  2015      0.009355   \n7248      10            0         89  0.014344  2009      0.006893   \n\n       Sales_Ranking  \n9592               1  \n1533               1  \n2003               1  \n2400               1  \n8433               1  \n...              ...  \n2032               1  \n10905              1  \n1121               2  \n6280               1  \n7248               1  \n\n[11348 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Genre</th>\n      <th>ESRB_Rating</th>\n      <th>Developer</th>\n      <th>NA_Sales</th>\n      <th>Year</th>\n      <th>Global_Sales</th>\n      <th>Sales_Ranking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9592</th>\n      <td>12</td>\n      <td>5</td>\n      <td>1355</td>\n      <td>0.005123</td>\n      <td>2002</td>\n      <td>0.002954</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1533</th>\n      <td>15</td>\n      <td>5</td>\n      <td>1570</td>\n      <td>0.047131</td>\n      <td>2006</td>\n      <td>0.047267</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2003</th>\n      <td>0</td>\n      <td>3</td>\n      <td>788</td>\n      <td>0.024590</td>\n      <td>2017</td>\n      <td>0.037912</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2400</th>\n      <td>13</td>\n      <td>5</td>\n      <td>926</td>\n      <td>0.017418</td>\n      <td>2005</td>\n      <td>0.032004</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8433</th>\n      <td>16</td>\n      <td>0</td>\n      <td>1763</td>\n      <td>0.010246</td>\n      <td>2009</td>\n      <td>0.004924</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2032</th>\n      <td>17</td>\n      <td>0</td>\n      <td>57</td>\n      <td>0.038934</td>\n      <td>2002</td>\n      <td>0.037420</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10905</th>\n      <td>10</td>\n      <td>0</td>\n      <td>126</td>\n      <td>0.003074</td>\n      <td>2004</td>\n      <td>0.001477</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1121</th>\n      <td>17</td>\n      <td>0</td>\n      <td>492</td>\n      <td>0.013320</td>\n      <td>2012</td>\n      <td>0.061054</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6280</th>\n      <td>1</td>\n      <td>1</td>\n      <td>181</td>\n      <td>0.011270</td>\n      <td>2015</td>\n      <td>0.009355</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7248</th>\n      <td>10</td>\n      <td>0</td>\n      <td>89</td>\n      <td>0.014344</td>\n      <td>2009</td>\n      <td>0.006893</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>11348 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training['Global_Sales'] = temp_df[0]\n",
    "df_for_training['NA_Sales'] = temp_df[1]\n",
    "df_for_training = df_for_training.dropna(subset = ['Global_Sales', 'NA_Sales'])\n",
    "df_for_training = df_for_training.reset_index(drop = True)\n",
    "df_for_training['Developer'] = le.fit_transform(df_for_training['Developer'])\n",
    "# Shuffle and reorder the dataframe\n",
    "df_for_training = df_for_training.sample(frac=1)[['Genre','ESRB_Rating','Developer','NA_Sales','Year','Global_Sales','Sales_Ranking']]\n",
    "df_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4.b Data Analysis and Visualization' <a name=\"data-ana-vis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Machine Learning Model <a name=\"ml-model\"></a>\n",
    "In this section, we are going to implement several models and predict global sales. In the world of machine learning, people\n",
    "can split datas into two groups: numerical data and categorical data. Numerical data is everything that represented by numbers (integer\n",
    "and floating point). It's continuous. Categorical data, however, is discrete. Different models will be used to predict these two type of data.\n",
    "\n",
    "It is obvious to predict sales as numerical data but we have the accuracy concern(we will see accuracy in the **Result Analysis and Demonstration** section)\n",
    "since the data may not demonstrate a strong linear trend. Therefore, we hope to predict it as categorical data: sale score is divided into 4 categories.\n",
    "Games in \">10\" category are expected to sell so greate that its name will left in history -- Grand Theft Auto, Pokemon, Call of duty and etc. You name it.\n",
    "Games in \"5-10\" category are sold less than the top ones, but they are still great games. \"5-1\" games are good games. there are still large amount of customer want to\n",
    "put them into their gaming library. The rest of games can be put into \"1-0\" categories. We respect the efforts that game developers put into them but they are relatively\n",
    "niche.\n",
    "### 5.a What and Why <a name=\"what-why\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We want to use *multiple linear regression* for predicting numerical sale number. The reason is that we intend to investigate\n",
    "how strong the relationship is between many independent variables (in this case, critic score, developers and other variables) and\n",
    "one dependent variable -- sale score. We made several assumptions for using multiple linear regression.\n",
    " - Homogeneity of Variance: the size of the error in our prediction doesn't change a lot\n",
    " - Independence of Observations: each game is independent of others.\n",
    " - Linearity: the line of best fit through the data point is a straight line.\n",
    "\n",
    "However, one potential issue is that there is no way we can check the linearity due to the fact that we have\n",
    "multiple categories. Therefore, we also hope to perform *multiple nonlinear regression*, i.e. we will fit a curve\n",
    "instead of a line for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Several models will be used for the prediction of categorical sale number: *Random forest*, *k-nearest neighbors* (KNN) and\n",
    "*Support vector machine*(SVM)\n",
    "\n",
    "Single decision tree suffers from a high variance, which makes them less accurate than other models. However, random forest fixes\n",
    "this problem. Benefits of using random forests:\n",
    " -  Bagging and bootstrap reduce the output variance\n",
    " -  Able to handle large dataset with high dimensionality (which is our datset)\n",
    "\n",
    "k-nearest neightbors, as one of the most famous classifications algorithm, surely have many positive sides:\n",
    " - No training period\n",
    " - Easily to add new data\n",
    " - Easy to implement\n",
    "\n",
    "Here is the advantages of choosing support vector machine as one of our algorithem.\n",
    " -  Effective in high dimensional spaces\n",
    " -  Use a subset of training set in the decision function and, therefore, prevent overfitting\n",
    " -  Memory efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.b Training <a name=\"training\"></a>\n",
    "**Multiple Linear Regression**\n",
    "We will use sklearn library for most of our training task. Non-linear regression is little bit tricky and we wish to use scipy library for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.optimize import curve_fit\n",
    "import sklearn\n",
    "\n",
    "# build model for numerical predictors\n",
    "muti_linear_regression = linear_model.LinearRegression(normalize=False,n_jobs=-1)\n",
    "muti_linear_regression_normalized = linear_model.LinearRegression(normalize=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Explanation:\n",
    "\n",
    "As for multiple linear regression, we have two models. One is non-modified x value and the other one is normalized x. Typically, we want to let each regressor have\n",
    "equal impact on the prediction so normalized is needed. Let's check the validation accuracy to see if it fits the hypothesis. The parameter \"n_jobs = -1\" means we want\n",
    "all processors to participate the computation given that we have relatively large dataset and many regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# build model for categorical predictors\n",
    "random_forest = RandomForestClassifier(n_estimators = 1000, random_state=42,max_depth=4,n_jobs = -1)\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "svm = sklearn.svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Explanation:\n",
    "\n",
    "To determine the number of trees (n_estimators in the function), we theoretically want as many trees as possible but the\n",
    "margin of accuracy of getting more than 1000 trees become neglectable. random_state will increase the randomness when the algorithm is\n",
    "bootstrapping.It is suggested that the maximum depth of the tree is sqrt(number of features), and also the\n",
    "more depth of a tree, the better it perform with diminishing returns. I will just choose 4 and the benefit of more than 4 is too small. The number of jobs indicates how many\n",
    "threads that are working in parallel.\n",
    "\n",
    "As for kNN, to determine the number of neighbors, I did several experiments. It turns out that n_neightbors = 5 can generate best output. Too small n_neightbor will result in\n",
    "unstable decision boundaries will too large will make the decision boundaries unclear.\n",
    "\n",
    "SVM is little bit intriguing. There are two options for us to set the \"decision_function_shape\". One is \"ovo\", which stands for one-verses-one, and the other option is called one-vs-the-rest.\n",
    "One-verse-one compare each classcifier with the predict value one by one while the one verse the rest option treats the x as a group and compare it with the y. In our case, we consider all the regressor\n",
    "as a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assign first several columns as X and last column as ground truth\n",
    "X = df_for_training.iloc[:, [0,1,2,4,5]]\n",
    "y_categorical = df_for_training[['Sales_Ranking']].to_numpy().flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_categorical.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Implement 10-fold cross validation\n",
    "rfr_score = model_selection.cross_val_score(random_forest, X, y, cv = 10)\n",
    "print(\"The average score for Random Forest is \", np.average(rfr_score))\n",
    "print(\"The standard error of the score is \", np.std(rfr_score))\n",
    "knn_score = model_selection.cross_val_score(knn, X, y, cv = 10)\n",
    "print(\"The average score for kNN is \", np.average(knn_score))\n",
    "print(\"The standard error of the score is \", np.std(knn_score))\n",
    "svm_score = model_selection.cross_val_score(svm,X, y, cv = 10)\n",
    "print(\"The average score for SVM is \", np.average(svm_score))\n",
    "print(\"The standard error of the score is \", np.std(svm_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Result Anlysis and Demonstration <a name=\"result-ana-demon\"></a>\n",
    "TODO:\n",
    "## 6. Future Application <a name=\"future-app\"></a>\n",
    "TODO:\n",
    "## 7. Reference and External Link <a name=\"ref-and-extlink\"></a>\n",
    "#### Want to to know more about multiple linear regression?\n",
    " - https://www.scribbr.com/statistics/multiple-linear-regression/\n",
    " - https://en.wikipedia.org/wiki/Linear_regression\n",
    " - https://towardsdatascience.com/understanding-multiple-regression-249b16bde83e\n",
    "\n",
    "#### Extend materials for support vector machine, Knn, random forest\n",
    " - https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47\n",
    " - https://www.youtube.com/watch?v=1NxnPkZM9bc\n",
    " - https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n",
    " - https://scikit-learn.org/stable/modules/svm.html\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7738021d",
   "language": "python",
   "display_name": "PyCharm (cmsc320fall2020)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}