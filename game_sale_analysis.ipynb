{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Siyuan \"Kevin\" Peng, Yuanzhe \"Siris\" Zheng, Yanlin \"Jacky\" Liu\n",
    "![Image of Yaktocat](https://cdn.mos.cms.futurecdn.net/rLh7Dh7EKo8F6zmDtXYp8W.jpg)\n",
    "# Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Install packages](#install-pkg)\n",
    "3. [Data Dowloading](#data-download)\n",
    "4. [Preprocessing](#preprocessing)<br>\n",
    "    a. [Load and Clean Dataset](#load-and-clean)<br>\n",
    "    b. [Data Analysis and Visualization](#data-ana-vis)\n",
    "5. [Machine Learning Model](#ml-model)<br>\n",
    "    a. [What and Why](#what-why)<br>\n",
    "    b. [Training](#training)<br>\n",
    "    c. [Result Anlysis and Demonstration](#result-and-demon)\n",
    "6. [Future Application](#future-app)\n",
    "7. [Reference and External Link](#ref-and-extlink)\n",
    "\n",
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Packages <a name=\"install-pkg\"></a>\n",
    "```\n",
    "pip install kaggle numpy matplotlib pandas sklearn\n",
    "```\n",
    "or use [environment.yml](https://github.com/syKevinPeng/game_sale_analysis/blob/main/environment.yml) to install packages in Conda environment\n",
    "```\n",
    "conda env update -f environment.yml\n",
    "```\n",
    "## 3. Data Downloading <a name=\"data-download\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-games-sales-2019.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "# remember to put kaggle.json to your C:/username/.kaggle\n",
    "!kaggle datasets download -d ashaheedq/video-games-sales-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "or directly download from kaggle webpage: [https://www.kaggle.com/ashaheedq/video-games-sales-2019](https://www.kaggle.com/ashaheedq/video-games-sales-2019)_\n",
    "## 4. Preprocessing <a name=\"preprocessing\"></a>\n",
    "### 4.a. Load and Clean Data <a name=\"load-and-clean\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   number                            game  release_date  price  \\\n0       1                     Half-Life 2  Nov 16, 2004   9.99   \n1       3          Counter-Strike: Source   Nov 1, 2004   9.99   \n2      21  Counter-Strike: Condition Zero   Mar 1, 2004   9.99   \n3      47         Half-Life 2: Deathmatch   Nov 1, 2004   4.99   \n4      36               Half-Life: Source   Jun 1, 2004   9.99   \n\n                     owners developer publisher  average_playtime  \\\n0  10,000,000 .. 20,000,000     Valve     Valve             110.0   \n1  10,000,000 .. 20,000,000     Valve     Valve             236.0   \n2  10,000,000 .. 20,000,000     Valve     Valve              10.0   \n3   5,000,000 .. 10,000,000     Valve     Valve               0.0   \n4    2,000,000 .. 5,000,000     Valve     Valve               0.0   \n\n   median_playtime  metascore  \n0             66.0       96.0  \n1            128.0       88.0  \n2              3.0       65.0  \n3              0.0        NaN  \n4              0.0        NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>game</th>\n      <th>release_date</th>\n      <th>price</th>\n      <th>owners</th>\n      <th>developer</th>\n      <th>publisher</th>\n      <th>average_playtime</th>\n      <th>median_playtime</th>\n      <th>metascore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Half-Life 2</td>\n      <td>Nov 16, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>110.0</td>\n      <td>66.0</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Counter-Strike: Source</td>\n      <td>Nov 1, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>236.0</td>\n      <td>128.0</td>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>Counter-Strike: Condition Zero</td>\n      <td>Mar 1, 2004</td>\n      <td>9.99</td>\n      <td>10,000,000 .. 20,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>65.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47</td>\n      <td>Half-Life 2: Deathmatch</td>\n      <td>Nov 1, 2004</td>\n      <td>4.99</td>\n      <td>5,000,000 .. 10,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36</td>\n      <td>Half-Life: Source</td>\n      <td>Jun 1, 2004</td>\n      <td>9.99</td>\n      <td>2,000,000 .. 5,000,000</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "import locale\n",
    "\n",
    "locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' ) \n",
    "df = pd.read_csv(\"vgsales-12-4-2019.csv\")\n",
    "additional = pd.read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv\")\n",
    "additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                             game  release_date owners developer publisher  \\\n0                     Half-Life 2  Nov 16, 2004      5     Valve     Valve   \n1          Counter-Strike: Source   Nov 1, 2004      5     Valve     Valve   \n2  Counter-Strike: Condition Zero   Mar 1, 2004      5     Valve     Valve   \n3         Half-Life 2: Deathmatch   Nov 1, 2004    2.5     Valve     Valve   \n4               Half-Life: Source   Jun 1, 2004    1.5     Valve     Valve   \n\n   metascore  Critic_Score  Year  \n0       96.0           9.6  2004  \n1       88.0           8.8  2004  \n2       65.0           6.5  2004  \n3        NaN           NaN  2004  \n4        NaN           NaN  2004  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game</th>\n      <th>release_date</th>\n      <th>owners</th>\n      <th>developer</th>\n      <th>publisher</th>\n      <th>metascore</th>\n      <th>Critic_Score</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Half-Life 2</td>\n      <td>Nov 16, 2004</td>\n      <td>5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>96.0</td>\n      <td>9.6</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Counter-Strike: Source</td>\n      <td>Nov 1, 2004</td>\n      <td>5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>88.0</td>\n      <td>8.8</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Counter-Strike: Condition Zero</td>\n      <td>Mar 1, 2004</td>\n      <td>5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>65.0</td>\n      <td>6.5</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Half-Life 2: Deathmatch</td>\n      <td>Nov 1, 2004</td>\n      <td>2.5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2004</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Half-Life: Source</td>\n      <td>Jun 1, 2004</td>\n      <td>1.5</td>\n      <td>Valve</td>\n      <td>Valve</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2004</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional = additional.dropna(subset = ['owners', 'release_date'])\n",
    "additional = additional.reset_index(drop = True)\n",
    "additional['Critic_Score'] = additional['metascore']/10\n",
    "additional['Year'] = additional['release_date']\n",
    "additional['owners'] = additional['owners'].astype(str)\n",
    "for i in range(len(additional)):\n",
    "    str(additional.loc[i, 'owners'])\n",
    "    nums = additional.loc[i, 'owners'].split('\\xa0..\\xa0')\n",
    "#     print(nums)\n",
    "    additional.loc[i, 'owners'] = float((locale.atoi(nums[1]) - locale.atoi(nums[0])) / 2000000)\n",
    "#     print(additional.loc[i, 'owners'])\n",
    "    temp = additional.loc[i, 'Year'].split(', ')\n",
    "    if len(temp) != 2:\n",
    "        additional.loc[i, 'Year'] = np.nan\n",
    "    else:\n",
    "        additional.loc[i, 'Year'] = int(temp[1])\n",
    "#     print(additional.loc[i, 'Year'].split(', ')[1])\n",
    "additional = additional.dropna(subset = ['release_date'])\n",
    "additional = additional.drop(columns = ['number', 'price', 'average_playtime', 'median_playtime'])\n",
    "additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                            Name     Genre ESRB_Rating         Developer  \\\n0                     Wii Sports    Sports           E      Nintendo EAD   \n1              Super Mario Bros.  Platform         NaN      Nintendo EAD   \n2                 Mario Kart Wii    Racing           E      Nintendo EAD   \n3  PlayerUnknown's Battlegrounds   Shooter         NaN  PUBG Corporation   \n4              Wii Sports Resort    Sports           E      Nintendo EAD   \n\n   Critic_Score  Global_Sales  NA_Sales  PAL_Sales  JP_Sales  Other_Sales  \\\n0           7.7           NaN       NaN        NaN       NaN          NaN   \n1          10.0           NaN       NaN        NaN       NaN          NaN   \n2           8.2           NaN       NaN        NaN       NaN          NaN   \n3           NaN           NaN       NaN        NaN       NaN          NaN   \n4           8.0           NaN       NaN        NaN       NaN          NaN   \n\n   Year  \n0  2006  \n1  1985  \n2  2008  \n3  2017  \n4  2009  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Genre</th>\n      <th>ESRB_Rating</th>\n      <th>Developer</th>\n      <th>Critic_Score</th>\n      <th>Global_Sales</th>\n      <th>NA_Sales</th>\n      <th>PAL_Sales</th>\n      <th>JP_Sales</th>\n      <th>Other_Sales</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wii Sports</td>\n      <td>Sports</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>7.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Super Mario Bros.</td>\n      <td>Platform</td>\n      <td>NaN</td>\n      <td>Nintendo EAD</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1985</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mario Kart Wii</td>\n      <td>Racing</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>8.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PlayerUnknown's Battlegrounds</td>\n      <td>Shooter</td>\n      <td>NaN</td>\n      <td>PUBG Corporation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2017</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wii Sports Resort</td>\n      <td>Sports</td>\n      <td>E</td>\n      <td>Nintendo EAD</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2009</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional['Name'] = additional['game']\n",
    "additional['Developer'] = additional['developer']\n",
    "additional['Global_Sales'] = additional['owners']\n",
    "df = df.dropna(subset = ['Year'])\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "additional = additional.drop(columns=['metascore', 'release_date', 'publisher', 'game', 'developer', 'owners'])\n",
    "df = df.drop(columns=['Rank', 'basename', 'Total_Shipped', 'Platform', 'Publisher', 'VGChartz_Score', \n",
    "                      'Last_Update', 'url', 'status', 'Vgchartzscore', 'img_url',  'User_Score'])\n",
    "pd.merge(df, additional, on = ['Name', 'Year'] , how = 'left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Developer', 'Genre'])\n",
    "df = df.reset_index(drop = True)\n",
    "df['Sales_Ranking'] = df['Global_Sales']\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'Developer'] = str(df.loc[i, 'Developer'])\n",
    "    if df.loc[i, 'Sales_Ranking'] >= 10:\n",
    "        df.loc[i, 'Sales_Ranking'] = 4\n",
    "    elif df.loc[i, 'Sales_Ranking'] >= 5 and df.loc[i, 'Sales_Ranking'] < 10:\n",
    "        df.loc[i, 'Sales_Ranking'] = 3\n",
    "    elif df.loc[i, 'Sales_Ranking'] >= 1 and df.loc[i, 'Sales_Ranking'] < 5:\n",
    "        df.loc[i, 'Sales_Ranking'] = 2\n",
    "    else:\n",
    "        df.loc[i, 'Sales_Ranking'] = 1\n",
    "le = LabelEncoder()\n",
    "# ohe = OneHotEncoder(handle_unknown = 'ignore')\n",
    "df['Sales_Ranking'] = df['Sales_Ranking'].astype(int)\n",
    "# df['Developer'] = le.fit_transform(df['Developer'])\n",
    "df['Genre'] = le.fit_transform(df['Genre'])\n",
    "df = df.dropna(subset=['Global_Sales', 'ESRB_Rating'])\n",
    "df['ESRB_Rating'] = le.fit_transform(df['ESRB_Rating'])\n",
    "# df_temp = pd.DataFrame(ohe.fit_transform(df[['Genre']]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = df.join(df_temp)\n",
    "\n",
    "df = df.reset_index(drop = True)\n",
    "df = df[df['Global_Sales'] != 0.0]\n",
    "df_for_visualization = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_training = df\n",
    "df_for_training = df.drop(columns = ['Name', 'PAL_Sales', 'JP_Sales', 'Other_Sales', 'Critic_Score'])\n",
    "df_for_training = df_for_training.dropna(subset = ['NA_Sales'])\n",
    "temp_df = df_for_training.drop(columns=['Genre', 'ESRB_Rating', 'Developer', 'Year', 'Sales_Ranking'])\n",
    "\n",
    "x = temp_df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "temp_df = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Genre  ESRB_Rating  Developer  NA_Sales  Year  Global_Sales  \\\n9592      12            5       1355  0.005123  2002      0.002954   \n1533      15            5       1570  0.047131  2006      0.047267   \n2003       0            3        788  0.024590  2017      0.037912   \n2400      13            5        926  0.017418  2005      0.032004   \n8433      16            0       1763  0.010246  2009      0.004924   \n...      ...          ...        ...       ...   ...           ...   \n2032      17            0         57  0.038934  2002      0.037420   \n10905     10            0        126  0.003074  2004      0.001477   \n1121      17            0        492  0.013320  2012      0.061054   \n6280       1            1        181  0.011270  2015      0.009355   \n7248      10            0         89  0.014344  2009      0.006893   \n\n       Sales_Ranking  \n9592               1  \n1533               1  \n2003               1  \n2400               1  \n8433               1  \n...              ...  \n2032               1  \n10905              1  \n1121               2  \n6280               1  \n7248               1  \n\n[11348 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Genre</th>\n      <th>ESRB_Rating</th>\n      <th>Developer</th>\n      <th>NA_Sales</th>\n      <th>Year</th>\n      <th>Global_Sales</th>\n      <th>Sales_Ranking</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9592</th>\n      <td>12</td>\n      <td>5</td>\n      <td>1355</td>\n      <td>0.005123</td>\n      <td>2002</td>\n      <td>0.002954</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1533</th>\n      <td>15</td>\n      <td>5</td>\n      <td>1570</td>\n      <td>0.047131</td>\n      <td>2006</td>\n      <td>0.047267</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2003</th>\n      <td>0</td>\n      <td>3</td>\n      <td>788</td>\n      <td>0.024590</td>\n      <td>2017</td>\n      <td>0.037912</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2400</th>\n      <td>13</td>\n      <td>5</td>\n      <td>926</td>\n      <td>0.017418</td>\n      <td>2005</td>\n      <td>0.032004</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8433</th>\n      <td>16</td>\n      <td>0</td>\n      <td>1763</td>\n      <td>0.010246</td>\n      <td>2009</td>\n      <td>0.004924</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2032</th>\n      <td>17</td>\n      <td>0</td>\n      <td>57</td>\n      <td>0.038934</td>\n      <td>2002</td>\n      <td>0.037420</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10905</th>\n      <td>10</td>\n      <td>0</td>\n      <td>126</td>\n      <td>0.003074</td>\n      <td>2004</td>\n      <td>0.001477</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1121</th>\n      <td>17</td>\n      <td>0</td>\n      <td>492</td>\n      <td>0.013320</td>\n      <td>2012</td>\n      <td>0.061054</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6280</th>\n      <td>1</td>\n      <td>1</td>\n      <td>181</td>\n      <td>0.011270</td>\n      <td>2015</td>\n      <td>0.009355</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7248</th>\n      <td>10</td>\n      <td>0</td>\n      <td>89</td>\n      <td>0.014344</td>\n      <td>2009</td>\n      <td>0.006893</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>11348 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_training['Global_Sales'] = temp_df[0]\n",
    "df_for_training['NA_Sales'] = temp_df[1]\n",
    "df_for_training = df_for_training.dropna(subset = ['Global_Sales', 'NA_Sales'])\n",
    "df_for_training = df_for_training.reset_index(drop = True)\n",
    "df_for_training['Developer'] = le.fit_transform(df_for_training['Developer'])\n",
    "# Shuffle and reorder the dataframe\n",
    "df_for_training = df_for_training.sample(frac=1)[['Genre','ESRB_Rating','Developer','NA_Sales','Year','Global_Sales','Sales_Ranking']]\n",
    "df_for_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### 4.b Data Analysis and Visualization' <a name=\"data-ana-vis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Machine Learning Model <a name=\"ml-model\"></a>\n",
    "In this section, we are going to implement several models and predict global sales. In the world of machine learning, people\n",
    "can split datas into two groups: numerical data and categorical data. Numerical data is everything that represented by numbers (integer\n",
    "and floating point). It's continuous. Categorical data, however, is discrete. Different models will be used to predict these two type of data.\n",
    "\n",
    "It is obvious to predict sales as numerical data but we have the accuracy concern(we will see accuracy in the **Result Analysis and Demonstration** section)\n",
    "since the data may not demonstrate a strong linear trend. Therefore, we hope to predict it as categorical data: sale score is divided into 4 categories.\n",
    "Games in \">10\" category are expected to sell so greate that its name will left in history -- Grand Theft Auto, Pokemon, Call of duty and etc. You name it.\n",
    "Games in \"5-10\" category are sold less than the top ones, but they are still great games. \"5-1\" games are good games. there are still large amount of customer want to\n",
    "put them into their gaming library. The rest of games can be put into \"1-0\" categories. We respect the efforts that game developers put into them but they are relatively\n",
    "niche.\n",
    "### 5.a What and Why <a name=\"what-why\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We want to use *multiple linear regression* for predicting numerical sale number. The reason is that we intend to investigate\n",
    "how strong the relationship is between many independent variables (in this case, critic score, developers and other variables) and\n",
    "one dependent variable -- sale score. We made several assumptions for using multiple linear regression.\n",
    " - Homogeneity of Variance: the size of the error in our prediction doesn't change a lot\n",
    " - Independence of Observations: each game is independent of others.\n",
    " - Linearity: the line of best fit through the data point is a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Several models will be used for the prediction of categorical sale number: *Random forest*, *k-nearest neighbors* (KNN) and\n",
    "*Support vector machine*(SVM)\n",
    "\n",
    "Single decision tree suffers from a high variance, which makes them less accurate than other models. However, random forest fixes\n",
    "this problem. Benefits of using random forests:\n",
    " -  Bagging and bootstrap reduce the output variance\n",
    " -  Able to handle large dataset with high dimensionality (which is our datset)\n",
    "\n",
    "k-nearest neightbors, as one of the most famous classifications algorithm, surely have many positive sides:\n",
    " - No training period\n",
    " - Easily to add new data\n",
    " - Easy to implement\n",
    "\n",
    "Here is the advantages of choosing support vector machine as one of our algorithem.\n",
    " -  Effective in high dimensional spaces\n",
    " -  Use a subset of training set in the decision function and, therefore, prevent overfitting\n",
    " -  Memory efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5.b Training <a name=\"training\"></a>\n",
    "**Multiple Linear Regression**\n",
    "We will use sklearn library for most of our training task. Non-linear regression is little bit tricky and we wish to use scipy library for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "\n",
    "# build model for numerical predictors\n",
    "muti_linear_regression = linear_model.LinearRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Explanation:\n",
    "\n",
    "This is a very simple and straight-forward model with n_jobs = -1, which means we want to use all available CPU cores for efficiency purpose"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# build model for categorical predictors\n",
    "random_forest = RandomForestClassifier(n_estimators = 1000, random_state=42,max_depth=4,n_jobs = -1)\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "svm = sklearn.svm.LinearSVC(max_iter=2000,dual=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Explanation:\n",
    "\n",
    "To determine the number of trees (n_estimators in the function), we theoretically want as many trees as possible but the\n",
    "margin of accuracy of getting more than 1000 trees become neglectable. random_state will increase the randomness when the algorithm is\n",
    "bootstrapping.It is suggested that the maximum depth of the tree is sqrt(number of features), and also the\n",
    "more depth of a tree, the better it perform with diminishing returns. I will just choose 4 and the benefit of more than 4 is too small. The number of jobs indicates how many\n",
    "threads that are working in parallel.\n",
    "\n",
    "As for kNN, to determine the number of neighbors, I did several experiments. It turns out that n_neightbors = 5 can generate best output. Too small n_neightbor will result in\n",
    "unstable decision boundaries will too large will make the decision boundaries unclear.\n",
    "\n",
    "SVM is little bit intriguing. There are two options for us to set the \"decision_function_shape\". One is \"ovo\", which stands for one-verses-one, and the other option is called one-vs-the-rest.\n",
    "One-verse-one compare each classcifier with the predict value one by one while the one verse the rest option treats the x as a group and compare it with the y. In our case, we consider all the regressor\n",
    "as a group. The reason why we set max_iter to 2000 is that it will not converge at default number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Assign first several columns as X and last two columns as ground truth\n",
    "X = df_for_training.iloc[:, 0:5]\n",
    "y_categorical = df_for_training[['Sales_Ranking']].to_numpy().flatten()\n",
    "y_numerical = df_for_training[['Global_Sales']].to_numpy().flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score for linear regression is  0.8389972878343632\n",
      "The standard error of the score is  0.02656213559835733\n"
     ]
    }
   ],
   "source": [
    "# numerical model\n",
    "# 10-fold cross validation for multi-linear regression:\n",
    "linear_score = []\n",
    "X = X.to_numpy()\n",
    "for train_index, test_index in model_selection.KFold(n_splits=10).split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_numerical[train_index], y_numerical[test_index]\n",
    "    model = muti_linear_regression.fit(X_train,y_train)\n",
    "    score = model.score(X_test,y_test)\n",
    "    linear_score.append(score)\n",
    "print('The average score for linear regression is ',np.average(linear_score))\n",
    "print(\"The standard error of the score is \", np.std(linear_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score for Random Forest is  0.9455400943212984\n",
      "The standard error of the score is  0.005250425986782506\n",
      "The average score for kNN is  0.8735466828271526\n",
      "The standard error of the score is  0.007593598713356333\n",
      "The average score for SVM is  0.8983963048427072\n",
      "The standard error of the score is  0.01175409018656301\n"
     ]
    }
   ],
   "source": [
    "# categorical model\n",
    "# Implement 10-fold cross validation\n",
    "rfr_score = model_selection.cross_val_score(random_forest, X, y_categorical, cv = 10)\n",
    "print(\"The average score for Random Forest is \", np.average(rfr_score))\n",
    "print(\"The standard error of the score is \", np.std(rfr_score))\n",
    "knn_score = model_selection.cross_val_score(knn, X, y_categorical, cv = 10)\n",
    "print(\"The average score for kNN is \", np.average(knn_score))\n",
    "print(\"The standard error of the score is \", np.std(knn_score))\n",
    "svm_score = model_selection.cross_val_score(svm,X, y_categorical, cv = 10)\n",
    "print(\"The average score for SVM is \", np.average(svm_score))\n",
    "print(\"The standard error of the score is \", np.std(svm_score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Result Anlysis and Demonstration <a name=\"result-and-demon\"></a>\n",
    "Below is the bar graph of accuracy score for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "models = ['linear_reg', 'radom forest', 'knn', 'svm']\n",
    "scores = [linear_score,rfr_score, knn_score,svm_score]\n",
    "accuracy = np.average(scores,axis=1)\n",
    "std = np.std(scores,axis=1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(models,accuracy,align = 'center',yerr = std, capsize=20)\n",
    "ax.set_xticks(models)\n",
    "ax.set_title('Accuracy of Four Models For Game Sale Prediction')\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel('Accuracy Score')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random forest model has the best accuracy score and I think bagging and bootstrap could be the reason why it outperformed other models.\n",
    "Also, the prediction for categorical variable generally better than the numerical prediction becuase, intuitively, predicting a category is\n",
    "easier than a specific number."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we are interested in the difference between two variables for the same subject, we are going to perform paired-t test for the predicted value and the ground truth to see\n",
    "the statistical difference between them. Our null hypothesis would be the average difference between the predicted value and ground truth is 0 and alternative hypothesis is the\n",
    "average difference is not 0. We choose alpha value = 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired t-test for random multi-linear regression is \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Ttest_relResult(statistic=1.2374634887003975e-13, pvalue=0.9999999999999013)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "muti_linear_regression.fit(X,y_categorical)\n",
    "pred_y = muti_linear_regression.predict(X)\n",
    "print(\"paired t-test for random multi-linear regression is \\n\")\n",
    "stats.ttest_rel(y_categorical, pred_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired t-test for random forest result is \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Ttest_relResult(statistic=9.064022064910278, pvalue=1.4630546520490245e-19)"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.fit(X,y_categorical)\n",
    "pred_y = random_forest.predict(X)\n",
    "print(\"paired t-test for random forest result is \\n\")\n",
    "stats.ttest_rel(y_categorical, pred_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired t-test for k nearest neighbor result is \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Ttest_relResult(statistic=23.45994627419661, pvalue=6.88479830215365e-119)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y_categorical)\n",
    "pred_y = knn.predict(X)\n",
    "print(\"paired t-test for k nearest neighbor result is \\n\")\n",
    "stats.ttest_rel(y_categorical, pred_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired t-test for support vector machine result is \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Ttest_relResult(statistic=39.954277306310075, pvalue=0.0)"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X,y_categorical)\n",
    "pred_y = svm.predict(X)\n",
    "print(\"paired t-test for support vector machine result is \\n\")\n",
    "stats.ttest_rel(y_categorical, pred_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From above result, it is interesting to see that we failed reject null hypothesis (i.e. there is no difference between\n",
    "the predicted value and ground truth for multi-linear regression paired-t test) but reject the null hypothesis (that is, there IS a difference)\n",
    "for the rest of three paired-t test. However, according to the accuracy score, random forest model achieved the highest. Why does this happen?\n",
    "\n",
    "According the formula that calculate t-value, we need to find the standard deviation of the difference between two groups. This standard deviation doesn't\n",
    "make sense when it comes to category. You can think it as using l2 loss (mean squared error) instead of cross-entropy loss for categorical problem. Therefore,\n",
    "we'd better directly use accuracy score for model-model comparison."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Future Application <a name=\"future-app\"></a>\n",
    "TODO:\n",
    "## 7. Reference and External Link <a name=\"ref-and-extlink\"></a>\n",
    "#### Want to to know more about multiple linear regression?\n",
    " - https://www.scribbr.com/statistics/multiple-linear-regression/\n",
    " - https://en.wikipedia.org/wiki/Linear_regression\n",
    " - https://towardsdatascience.com/understanding-multiple-regression-249b16bde83e\n",
    "\n",
    "#### Extend materials for support vector machine, Knn, random forest\n",
    " - https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47\n",
    " - https://www.youtube.com/watch?v=1NxnPkZM9bc\n",
    " - https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761\n",
    " - https://scikit-learn.org/stable/modules/svm.html\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    " - https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "#### paired-t test reading:\n",
    " - https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/SAS/SAS4-OneSampleTtest/SAS4-OneSampleTtest7.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7738021d",
   "language": "python",
   "display_name": "PyCharm (cmsc320fall2020)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}